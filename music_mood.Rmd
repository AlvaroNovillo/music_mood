---
output: 
  stevetemplates::article:
    fig_caption: true
    latex_engine: pdflatex
    citation_package: natbib
    keep_tex: yes
    extra_dependencies: ["graphicx", "hyperref","float"]
bibliography: master.bib
biblio-style: apsr
title: "Mood-Based Song Classifier."
thanks: "Replication files are available on the author's Github account (https://github.com/AlvaroNovillo/music_mood). **Current version**: `r format(Sys.time(), '%B %d, %Y')`; **Corresponding author**: novillocorreasalvaro@gmail.com."
author:
- name: √Ålvaro Novillo Correas
  affiliation: Universidad Carlos III
abstract: "TO AD."
keywords: "pandoc, r markdown, knitr"
date: "`r format(Sys.time(), '%B %d, %Y')`"
geometry: margin=1in
fontfamily: mathpazo
fontsize: 11pt
# spacing: double
endnote: no
link-citations: true 
---


```{r setup, include=FALSE}
# Load and install required libraries

packages <- c("ggplot2","stevetemplates","kableExtra","glmnet", "fmsb","caret","tidyr","dplyr")

# Install packages not yet installed
installed_packages <- packages %in% rownames(installed.packages())
if (any(installed_packages == FALSE)) {
  install.packages(packages[!installed_packages])
}

# Packages loading
invisible(lapply(packages, library, character.only = TRUE))

#kableExtra options
options(kableExtra.latex.load_packages = TRUE)

#knitr document options
tidy.opts = list(width.cutoff = 80)
knitr::opts_chunk$set(cache=TRUE, echo = FALSE,
                      message=FALSE, warning=FALSE,
                      time_it = TRUE,
                      fig.pos = "H", out.extra = "",
                      fig.path='figs/',
                      cache.path = '_cache/',
                      fig.process = function(x) {
                      x2 = sub('-\\d+([.][a-z]+)$', '\\1', x)
                      if (file.rename(x, x2)) x2 else x
                      })


# Set graphic colors
library(RColorBrewer)
coul <- brewer.pal(4, "Spectral")
colors_border <- coul
library(scales)
colors_in <- alpha(coul,0.4)

```

#EDA

Following the steps of [@data1], we will use a dataset^[1] of 686 classified songs into four emotions: energetic, happy, calm, and sad. We will then use various machine learning techniques to train a model that can classify the mood of a song based on specific

parameters.

Using data scraped from [Spotify](https://open.spotify.com/intl-es), we will create a tool to perform basic exploratory data analysis on the songs. We will then use our classification algorithm to categorise the songs.

ADD CORRELATION MATRIX
ADD EXPLANATION OF THE DATASET 
ADD MODELS
ADD HISTOGRAMS 


```{r}
music_data <- read.csv(file = 'data_moods.csv', header=TRUE,sep = ',')

music_data <- subset(music_data, select = c("name","artist", "album","id", "danceability", "acousticness", "energy", "instrumentalness", "liveness", "valence", "loudness", "speechiness", "tempo","mood"))

```

```{r}
# Check the distribution of songs across different moods
mood_counts <- table(music_data$mood)

# Plot the distribution of songs across different moods
h <- ggplot(data = data.frame(mood = names(mood_counts), count = as.numeric(mood_counts)), aes(x = mood, y = count, fill = mood)) +
  geom_bar(stat = "identity") +
  labs(x = "Mood",
       y = "Number of Songs") +
  theme_minimal() +
  theme(axis.text.x = element_text(angle = 45, hjust = 1))

h + scale_fill_manual(values=coul) + theme(legend.text = element_text(face = "italic"), legend.title = element_text(size = 12,face = "bold.italic", family = "Helvetica"),
    panel.background = element_rect(fill = NA)) + theme(axis.title = element_text(family = "sans"),
    axis.text = element_text(family = "sans"),
    plot.title = element_text(family = "sans"),
    legend.text = element_text(family = "sans"),
    legend.title = element_text(family = "sans"))
```
```{r}
# Load necessary libraries
library(ggplot2)
library(dplyr)
library(tidyr)


# Select the required variables
vars_of_interest <- c("danceability", "acousticness", "energy", "instrumentalness", "liveness", "valence", "loudness", "speechiness")

averages <- music_data %>%
  group_by(mood) %>%
  summarise(across(vars_of_interest, mean))


averages <- as.data.frame(averages)
rownames(averages) <- averages$mood



radarchart(averages[,-1]  , axistype=0 , maxmin=F,
    #custom polygon
    pcol=colors_border , pfcol=colors_in , plwd=4 , plty=1,
    #custom the grid
    cglcol="grey", cglty=1, axislabcol="black", cglwd=0.8, 
    #custom labels
    vlcex=0.8 
    )


# Add a legend
legend(x=2, y=1, legend = rownames(averages), bty = "n", pch=20 , col=colors_in , text.col = "grey", cex=1.2, pt.cex=3)
```

#Methodolody

```{r}
numeric_data <- subset(music_data, select = c("danceability", "acousticness", "energy", "instrumentalness", "liveness", "valence", "loudness", "speechiness", "tempo","mood"))

spl = createDataPartition(numeric_data$mood, p = 0.8, list = FALSE)  # 80% for training

Train = numeric_data[spl,]
Test = numeric_data[-spl,]
```


## Logistic regression

```{r,warning=FALSE}
log.fit = train(mood ~ ., method= "multinom", data = Train, trControl = trainControl(method = "cv"))

```

```{r}
# Predict on the test dataset
predictions <- predict(log.fit, newdata = Test)

# Compute the confusion matrix
confusion_matrix <- confusionMatrix(predictions, as.factor(Test$mood))
print(confusion_matrix)

```
```{r}
log.fit = train(mood ~ ., method= "multinom", data = numeric_data, trControl = trainControl(method = "cv"))
# Save the trained model
saveRDS(log.fit, "trained_model.rds")

```



[^1]: The dataset used to train our model can be found in [Kaggle](https://www.kaggle.com/datasets/musicblogger/spotify-music-data-to-identify-the-moods)
<!--
# References
\setlength{\parindent}{-0.2in}
\setlength{\leftskip}{0.2in}
\setlength{\parskip}{8pt}
\vspace*{-0.2in}
\noindent
-->
